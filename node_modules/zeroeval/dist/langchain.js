import {
  getLogger,
  tracer
} from "./chunk-2VY765DQ.js";
import "./chunk-P57PW2II.js";

// src/observability/integrations/langchain/ZeroEvalCallbackHandler.ts
import { BaseCallbackHandler } from "@langchain/core/callbacks/base";
import { ToolMessage } from "@langchain/core/messages";
var logger = getLogger("zeroeval.langchain");
var ObjectPool = class {
  constructor(factory, reset, maxSize = 100) {
    this.pool = [];
    this.factory = factory;
    this.reset = reset;
    this.maxSize = maxSize;
  }
  acquire() {
    return this.pool.pop() || this.factory();
  }
  release(obj) {
    if (this.pool.length < this.maxSize) {
      this.reset(obj);
      this.pool.push(obj);
    }
  }
};
var LazySerializer = class {
  constructor(value) {
    this.value = value;
  }
  toString() {
    if (!this.serialized) {
      this.serialized = typeof this.value === "string" ? this.value : JSON.stringify(this.value);
    }
    return this.serialized;
  }
};
var _ZeroEvalCallbackHandler = class _ZeroEvalCallbackHandler extends BaseCallbackHandler {
  constructor(options) {
    super();
    this.name = "ZeroEvalCallbackHandler";
    this.spans = /* @__PURE__ */ new Map();
    this.spanStartTimes = /* @__PURE__ */ new Map();
    this.options = {
      debug: options?.debug ?? false,
      excludeMetadataProps: options?.excludeMetadataProps ?? /^(l[sc]_|langgraph_|__pregel_|checkpoint_ns)/,
      maxConcurrentSpans: options?.maxConcurrentSpans ?? 1e3,
      spanCleanupIntervalMs: options?.spanCleanupIntervalMs ?? 6e4
    };
    this.cachedRegex = this.options.excludeMetadataProps;
    this.metadataPool = new ObjectPool(
      () => ({}),
      (obj) => {
        Object.keys(obj).forEach((key) => delete obj[key]);
      }
    );
    this.startCleanupTimer();
  }
  startCleanupTimer() {
    this.cleanupTimer = setInterval(() => {
      this.cleanupOrphanedSpans();
    }, this.options.spanCleanupIntervalMs);
    this.cleanupTimer.unref();
  }
  cleanupOrphanedSpans() {
    const now = Date.now();
    const maxAge = 5 * 60 * 1e3;
    for (const [runId, startTime] of this.spanStartTimes) {
      if (now - startTime > maxAge) {
        const span = this.spans.get(runId);
        if (span) {
          span.setError({
            message: "Span orphaned - auto-cleaned after timeout"
          });
          tracer.endSpan(span);
        }
        this.spans.delete(runId);
        this.spanStartTimes.delete(runId);
      }
    }
  }
  startSpan({
    runId,
    parentRunId,
    name,
    type,
    input,
    tags,
    metadata
  }) {
    if (this.spans.has(runId)) {
      logger.warn(`Span already exists for runId ${runId}`);
      return;
    }
    if (this.spans.size >= this.options.maxConcurrentSpans) {
      logger.warn(
        `Max concurrent spans (${this.options.maxConcurrentSpans}) reached`
      );
      return;
    }
    if (!parentRunId) {
      this.rootRunId = runId;
    }
    const attributes = this.metadataPool.acquire();
    if (type)
      attributes.type = type;
    if (tags)
      attributes.tags = tags;
    if (type === "llm") {
      attributes.kind = "llm";
      if (attributes.provider === void 0) {
        attributes.provider = "openai";
      }
      if (attributes["service.name"] === void 0) {
        attributes["service.name"] = attributes.provider;
      }
    }
    if (metadata) {
      for (const [key, value] of Object.entries(metadata)) {
        if (!this.cachedRegex.test(key)) {
          attributes[key] = value;
        }
      }
    }
    if (this.options.debug) {
      attributes.runId = runId;
      attributes.parentRunId = parentRunId;
    }
    const spanTags = { integration: "langchain" };
    if (type)
      spanTags[`langchain.${type}`] = "true";
    const span = tracer.startSpan(name, {
      attributes,
      tags: spanTags
    });
    if (input !== void 0) {
      const lazyInput = new LazySerializer(input);
      span.setIO(lazyInput.toString(), void 0);
    }
    this.spans.set(runId, span);
    this.spanStartTimes.set(runId, Date.now());
    this.metadataPool.release(attributes);
  }
  endSpan({
    runId,
    output,
    error,
    tags,
    metadata
  }) {
    const span = this.spans.get(runId);
    if (!span) {
      logger.warn(`No span exists for runId ${runId}`);
      return;
    }
    this.spans.delete(runId);
    this.spanStartTimes.delete(runId);
    if (runId === this.rootRunId) {
      this.rootRunId = void 0;
    }
    if (output !== void 0) {
      const lazyOutput = new LazySerializer(output);
      span.setIO(span.inputData, lazyOutput.toString());
    }
    if (error) {
      span.setError({ message: error });
    }
    if (tags || metadata) {
      const additionalAttrs = this.metadataPool.acquire();
      if (tags)
        additionalAttrs.tags = tags;
      if (metadata) {
        for (const [key, value] of Object.entries(metadata)) {
          if (!this.cachedRegex.test(key)) {
            additionalAttrs[key] = value;
          }
        }
      }
      Object.assign(span.attributes, additionalAttrs);
      this.metadataPool.release(additionalAttrs);
    }
    span.end();
    if (span.attributes.outputTokens && span.durationMs && span.durationMs > 0) {
      const outputTokens = span.attributes.outputTokens;
      span.attributes.throughput = Math.round(outputTokens / (span.durationMs / 1e3) * 100) / 100;
    }
    tracer.endSpan(span);
  }
  beginTracerSegment({
    runId,
    parentRunId,
    type,
    name,
    input,
    tags,
    metadata
  }) {
    this.startSpan({
      runId,
      parentRunId,
      name,
      type,
      input,
      tags,
      metadata
    });
  }
  finishTracerSegment({
    runId,
    output,
    error,
    tags,
    metadata
  }) {
    this.endSpan({ runId, output, error, tags, metadata });
  }
  deriveComponentName(serialized, fallback) {
    const lastId = serialized.id[serialized.id.length - 1];
    return lastId?.toString() ?? fallback;
  }
  async handleLLMStart(llm, prompts, runId, parentRunId, extraParams, tags, metadata, runName) {
    const normalizedMetadata = metadata ? this.metadataPool.acquire() : {};
    if (metadata)
      Object.assign(normalizedMetadata, metadata);
    const invocationParams = extraParams?.invocation_params || {};
    const callParams = this.normalizeCallParamsOptimized(
      llm,
      invocationParams,
      metadata
    );
    Object.assign(normalizedMetadata, callParams);
    this.beginTracerSegment({
      runId,
      parentRunId,
      type: "llm",
      name: runName ?? this.deriveComponentName(llm, "LLM"),
      input: prompts,
      tags,
      metadata: normalizedMetadata
    });
    if (metadata)
      this.metadataPool.release(normalizedMetadata);
  }
  async handleLLMError(err, runId, parentRunId, tags) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({ runId, error: err.message, tags });
    }
  }
  async handleLLMEnd(output, runId, parentRunId, tags) {
    const span = this.spans.get(runId);
    if (!span)
      return;
    const { llmOutput, generations, ...metadata } = output;
    const tokenUsage = llmOutput?.tokenUsage || llmOutput?.estimatedTokens || {};
    if (tokenUsage.totalTokens || tokenUsage.promptTokens || tokenUsage.completionTokens) {
      if (tokenUsage.promptTokens) {
        span.attributes.inputTokens = tokenUsage.promptTokens;
      }
      if (tokenUsage.completionTokens) {
        span.attributes.outputTokens = tokenUsage.completionTokens;
      }
      if (!span.attributes.metrics) {
        span.attributes.metrics = {};
      }
      const metrics = span.attributes.metrics;
      if (tokenUsage.totalTokens)
        metrics.tokens = tokenUsage.totalTokens;
      if (tokenUsage.promptTokens)
        metrics.prompt_tokens = tokenUsage.promptTokens;
      if (tokenUsage.completionTokens)
        metrics.completion_tokens = tokenUsage.completionTokens;
    }
    this.finishTracerSegment({
      runId,
      output: this.flattenGenerationsOptimized(generations),
      tags,
      metadata
    });
  }
  async handleChatModelStart(llm, messages, runId, parentRunId, extraParams, tags, metadata, runName) {
    const normalizedMetadata = this.metadataPool.acquire();
    if (metadata)
      Object.assign(normalizedMetadata, metadata);
    const invocationParams = extraParams?.invocation_params || {};
    const callParams = this.normalizeCallParamsOptimized(
      llm,
      invocationParams,
      metadata
    );
    Object.assign(normalizedMetadata, callParams);
    if (invocationParams.tools) {
      normalizedMetadata.tools = invocationParams.tools;
    }
    const flattenedMessages = this.flattenMessagesInputOptimized(messages);
    normalizedMetadata.messages = flattenedMessages;
    this.beginTracerSegment({
      runId,
      parentRunId,
      type: "llm",
      name: runName ?? this.deriveComponentName(llm, "Chat Model"),
      input: this.flattenMessagesInputOptimized(messages),
      tags,
      metadata: normalizedMetadata
    });
    this.metadataPool.release(normalizedMetadata);
  }
  async handleChainStart(chain, inputs, runId, parentRunId, tags, metadata, runType, runName) {
    if (tags?.includes("langsmith:hidden")) {
      return;
    }
    this.beginTracerSegment({
      runId,
      parentRunId,
      type: "chain",
      name: runName ?? this.deriveComponentName(chain, "Chain"),
      input: this.normalizeChainInputsOptimized(inputs),
      tags,
      metadata: {
        ...metadata,
        ...this.normalizeCallParamsOptimized(chain, {}, metadata)
      }
    });
  }
  async handleChainError(err, runId, parentRunId, tags, kwargs) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({ runId, error: err.toString(), tags });
    }
  }
  async handleChainEnd(outputs, runId, parentRunId, tags, kwargs) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({
        runId,
        tags,
        output: this.normalizeChainOutputsOptimized(outputs)
      });
    }
  }
  async handleToolStart(tool, input, runId, parentRunId, tags, metadata, runName) {
    this.beginTracerSegment({
      runId,
      parentRunId,
      type: "tool",
      name: runName ?? this.deriveComponentName(tool, "Tool"),
      input: this.parseMaybeJsonOptimized(input),
      tags,
      metadata: {
        ...metadata,
        ...this.normalizeCallParamsOptimized(tool, {}, metadata)
      }
    });
  }
  async handleToolError(err, runId, parentRunId, tags) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({ runId, error: err.message, tags });
    }
  }
  async handleToolEnd(output, runId, parentRunId, tags) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({
        runId,
        output: this.normalizeToolOutputOptimized(output),
        tags
      });
    }
  }
  async handleAgentAction(action, runId, parentRunId, tags) {
    this.beginTracerSegment({
      runId,
      parentRunId,
      type: "agent",
      name: action.tool,
      input: action,
      tags
    });
  }
  async handleAgentEnd(action, runId, parentRunId, tags) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({ runId, output: action, tags });
    }
  }
  async handleRetrieverStart(retriever, query, runId, parentRunId, tags, metadata, name) {
    this.beginTracerSegment({
      runId,
      parentRunId,
      type: "retriever",
      name: name ?? this.deriveComponentName(retriever, "Retriever"),
      input: query,
      tags,
      metadata: {
        ...metadata,
        ...this.normalizeCallParamsOptimized(retriever, {}, metadata)
      }
    });
  }
  async handleRetrieverEnd(documents, runId, parentRunId, tags) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({ runId, output: documents, tags });
    }
  }
  async handleRetrieverError(err, runId, parentRunId, tags) {
    if (this.spans.has(runId)) {
      this.finishTracerSegment({ runId, error: err.message, tags });
    }
  }
  // Optimized helper functions
  normalizeCallParamsOptimized(llm, invocationParams, metadata) {
    const args = this.metadataPool.acquire();
    const model = _ZeroEvalCallbackHandler.chooseFirst(
      invocationParams?.model,
      metadata?.ls_model_name,
      llm.name
    );
    if (model !== void 0)
      args.model = model;
    const temperature = _ZeroEvalCallbackHandler.chooseFirst(
      invocationParams?.temperature,
      metadata?.ls_temperature
    );
    if (temperature !== void 0)
      args.temperature = temperature;
    const params = [
      ["top_p", invocationParams?.top_p ?? invocationParams?.topP],
      ["top_k", invocationParams?.top_k ?? invocationParams?.topK],
      [
        "max_tokens",
        invocationParams?.max_tokens ?? invocationParams?.maxOutputTokens
      ],
      ["frequency_penalty", invocationParams?.frequency_penalty],
      ["presence_penalty", invocationParams?.presence_penalty],
      ["response_format", invocationParams?.response_format],
      ["tool_choice", invocationParams?.tool_choice],
      ["function_call", invocationParams?.function_call],
      ["n", invocationParams?.n],
      ["stop", invocationParams?.stop ?? invocationParams?.stop_sequence]
    ];
    for (const [key, value] of params) {
      if (value !== void 0 && value !== null) {
        args[key] = value;
      }
    }
    const result = Object.keys(args).length ? { ...args } : invocationParams;
    this.metadataPool.release(args);
    return result;
  }
  flattenGenerationsOptimized(generations) {
    const result = [];
    for (const batch of generations) {
      if (Array.isArray(batch)) {
        for (const gen of batch) {
          const parsed = this.parseGenOptimized(gen);
          if (parsed !== void 0)
            result.push(parsed);
        }
      } else {
        const parsed = this.parseGenOptimized(batch);
        if (parsed !== void 0)
          result.push(parsed);
      }
    }
    return result;
  }
  parseGenOptimized(generation) {
    if ("message" in generation) {
      return this.extractMessageContentOptimized(generation.message);
    }
    return generation.text;
  }
  flattenMessagesInputOptimized(messages) {
    const result = [];
    for (const batch of messages) {
      for (const message of batch) {
        result.push(this.extractMessageContentOptimized(message));
      }
    }
    return result;
  }
  extractMessageContentOptimized(message) {
    const result = this.metadataPool.acquire();
    result.content = message.content;
    const messageType = message._getType();
    let role = message.name ?? messageType;
    if (messageType === "human")
      role = "user";
    else if (messageType === "ai")
      role = "assistant";
    else if (messageType === "system")
      role = "system";
    result.role = role;
    const anyMessage = message;
    if (anyMessage.tool_calls)
      result.tool_calls = anyMessage.tool_calls;
    if (anyMessage.status)
      result.status = anyMessage.status;
    if (anyMessage.artifact)
      result.artifact = anyMessage.artifact;
    const copy = { ...result };
    this.metadataPool.release(result);
    return copy;
  }
  parseMaybeJsonOptimized(input) {
    try {
      return JSON.parse(input);
    } catch {
      return input;
    }
  }
  normalizeToolOutputOptimized(output) {
    return output instanceof ToolMessage ? this.extractMessageContentOptimized(output) : output;
  }
  normalizeChainOutputsOptimized(output) {
    const parsed = (Array.isArray(output) ? output : [output]).map(
      (item) => this.parseChainElementOptimized(item)
    );
    return parsed.length === 1 ? parsed[0] : parsed;
  }
  normalizeChainInputsOptimized(inputs) {
    const parsed = (Array.isArray(inputs) ? inputs : [inputs]).map(
      (item) => this.parseChainElementOptimized(item)
    );
    return parsed.length === 1 ? parsed[0] : parsed;
  }
  parseChainElementOptimized(output) {
    if (typeof output === "string") {
      return output;
    }
    if (!output) {
      return output;
    }
    if (output.content) {
      return output.content;
    }
    if (output.messages) {
      return output.messages.map(
        (msg) => this.parseChainElementOptimized(msg)
      );
    }
    if (output.value) {
      return output.value;
    }
    if (output.kwargs) {
      return this.parseChainElementOptimized(output.kwargs);
    }
    if (typeof output === "object" && output) {
      const result = this.metadataPool.acquire();
      for (const [key, value] of Object.entries(output)) {
        result[key] = this.parseChainElementOptimized(value);
      }
      const copy = { ...result };
      this.metadataPool.release(result);
      return copy;
    }
    return output;
  }
  destroy() {
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
    }
    for (const span of this.spans.values()) {
      span.setError({ message: "Handler destroyed with active span" });
      tracer.endSpan(span);
    }
    this.spans.clear();
    this.spanStartTimes.clear();
  }
};
_ZeroEvalCallbackHandler.chooseFirst = (...values) => {
  for (const value of values) {
    if (value !== void 0 && value !== null)
      return value;
  }
  return void 0;
};
var ZeroEvalCallbackHandler = _ZeroEvalCallbackHandler;

// src/observability/integrations/langchain/setGlobalCallbackHandler.ts
var globalHandler;
var setGlobalCallbackHandler = (handler) => {
  globalHandler = handler;
};
var getGlobalHandler = () => {
  return globalHandler;
};
var clearGlobalHandler = () => {
  globalHandler = void 0;
};
export {
  ZeroEvalCallbackHandler,
  clearGlobalHandler,
  getGlobalHandler,
  setGlobalCallbackHandler
};
